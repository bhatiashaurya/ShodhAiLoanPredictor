{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1902bc",
   "metadata": {},
   "source": [
    "# Loan Default Prediction: Deep Learning vs Offline Reinforcement Learning\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Business Context:** As a Research Scientist at a fintech company, we aim to improve the loan approval process to maximize financial returns while managing default risk.\n",
    "\n",
    "**Objective:** Build and compare two approaches:\n",
    "1. **Supervised Deep Learning Model**: Predicts probability of loan default\n",
    "2. **Offline Reinforcement Learning Agent**: Learns a policy to maximize expected financial return\n",
    "\n",
    "**Dataset:** Historical loan data from 2007-2018 including applicant details and loan outcomes\n",
    "\n",
    "---\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "### Task 1: Exploratory Data Analysis & Preprocessing\n",
    "- Data exploration and feature understanding\n",
    "- Feature engineering and selection\n",
    "- Data cleaning and preprocessing\n",
    "\n",
    "### Task 2: Deep Learning Classification Model\n",
    "- Binary classification: Fully Paid (0) vs Defaulted (1)\n",
    "- Multi-Layer Perceptron with PyTorch\n",
    "- Evaluation: AUC-ROC, F1-Score\n",
    "\n",
    "### Task 3: Offline Reinforcement Learning Agent\n",
    "- Frame as offline RL problem\n",
    "- Define state, action, and reward\n",
    "- Train using modern offline RL algorithm\n",
    "- Evaluation: Estimated Policy Value\n",
    "\n",
    "### Task 4: Analysis & Comparison\n",
    "- Compare model predictions and policies\n",
    "- Analyze business implications\n",
    "- Propose future improvements\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203f660",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Machine Learning - Metrics\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "# Deep Learning - PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e95ecc",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset\n",
    "\n",
    "The dataset is large (~1.6GB), so we'll use efficient loading strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9fd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path\n",
    "DATA_PATH = Path(\"shodhAI_dataset/accepted_2007_to_2018q4.csv/accepted_2007_to_2018Q4.csv\")\n",
    "\n",
    "# First, let's load a preview to understand the structure\n",
    "print(\"Loading dataset preview...\")\n",
    "df_preview = pd.read_csv(DATA_PATH, nrows=5000)\n",
    "\n",
    "print(f\"Dataset preview shape: {df_preview.shape}\")\n",
    "print(f\"Total columns: {df_preview.shape[1]}\")\n",
    "print(f\"\\nFirst few column names:\")\n",
    "print(df_preview.columns.tolist()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the target variable distribution\n",
    "print(\"Loan Status Distribution (preview):\")\n",
    "print(df_preview['loan_status'].value_counts())\n",
    "print(f\"\\nPercentage:\")\n",
    "print(df_preview['loan_status'].value_counts(normalize=True).round(4) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0fe9d",
   "metadata": {},
   "source": [
    "### Feature Selection Strategy\n",
    "\n",
    "Based on domain knowledge and predictive power for loan default, we'll select the following features:\n",
    "\n",
    "**Loan Characteristics:**\n",
    "- `loan_amnt`: Loan amount\n",
    "- `term`: Loan term (36/60 months)\n",
    "- `int_rate`: Interest rate\n",
    "- `installment`: Monthly payment\n",
    "- `grade`, `sub_grade`: Loan risk grade\n",
    "\n",
    "**Borrower Financial Profile:**\n",
    "- `annual_inc`: Annual income\n",
    "- `dti`: Debt-to-income ratio\n",
    "- `revol_bal`, `revol_util`: Revolving credit utilization\n",
    "- `total_acc`, `open_acc`: Number of credit accounts\n",
    "\n",
    "**Credit History:**\n",
    "- `delinq_2yrs`: Past delinquencies\n",
    "- `pub_rec`, `pub_rec_bankruptcies`: Public records\n",
    "- `inq_last_6mths`: Recent credit inquiries\n",
    "- `fico_range_low`, `fico_range_high`: FICO score\n",
    "\n",
    "**Other:**\n",
    "- `emp_length`: Employment length\n",
    "- `home_ownership`: Home ownership status\n",
    "- `verification_status`: Income verification\n",
    "- `purpose`: Loan purpose\n",
    "- `loan_status`: **TARGET VARIABLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce06fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define selected features\n",
    "SELECTED_FEATURES = [\n",
    "    # Loan characteristics\n",
    "    'loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
    "    \n",
    "    # Borrower financial profile\n",
    "    'annual_inc', 'dti', 'revol_bal', 'revol_util', 'total_acc', 'open_acc',\n",
    "    \n",
    "    # Credit history\n",
    "    'delinq_2yrs', 'pub_rec', 'pub_rec_bankruptcies', 'inq_last_6mths',\n",
    "    'fico_range_low', 'fico_range_high',\n",
    "    \n",
    "    # Other features\n",
    "    'emp_length', 'home_ownership', 'verification_status', 'purpose',\n",
    "    \n",
    "    # Target\n",
    "    'loan_status'\n",
    "]\n",
    "\n",
    "# Check which features are available in the dataset\n",
    "available_features = [col for col in SELECTED_FEATURES if col in df_preview.columns]\n",
    "missing_features = [col for col in SELECTED_FEATURES if col not in df_preview.columns]\n",
    "\n",
    "print(f\"Available features: {len(available_features)}/{len(SELECTED_FEATURES)}\")\n",
    "if missing_features:\n",
    "    print(f\"Missing features: {missing_features}\")\n",
    "    \n",
    "print(f\"\\nLoading full dataset with {len(available_features)} selected features...\")\n",
    "print(\"This may take 1-2 minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a25a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset with selected features\n",
    "df = pd.read_csv(DATA_PATH, usecols=available_features, low_memory=False)\n",
    "\n",
    "print(f\"✓ Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59591f26",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print(\"=\" * 80)\n",
    "print(\"LOAN STATUS DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "status_counts = df['loan_status'].value_counts()\n",
    "status_pct = df['loan_status'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nAbsolute counts:\")\n",
    "print(status_counts)\n",
    "print(\"\\nPercentage:\")\n",
    "print(status_pct.round(2))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Count plot\n",
    "status_counts.plot(kind='bar', ax=axes[0], color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Loan Status Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Loan Status')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(status_pct, labels=status_pct.index, autopct='%1.1f%%', \n",
    "            startangle=90, colors=sns.color_palette('pastel'))\n",
    "axes[1].set_title('Loan Status Percentage', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ecba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features\n",
    "print(\"=\" * 80)\n",
    "print(\"NUMERICAL FEATURES - STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2fabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_pct.index,\n",
    "    'Missing_Percentage': missing_pct.values\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"Top 10 columns with missing values:\")\n",
    "print(missing_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ad2f3",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Preprocessing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
